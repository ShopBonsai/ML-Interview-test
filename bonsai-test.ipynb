{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import implicit\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'training_mixpanel.txt'\n",
    "with open(data_dir) as f:\n",
    "    purchase_data = json.load(f)\n",
    "data = [item['properties'] for item in purchase_data]\n",
    "df_raw = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>description</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>6</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>6</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>SET 7 BABUSHKA NESTING BOXES</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>536365</td>\n",
       "      <td>22752</td>\n",
       "      <td>2</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>536365</td>\n",
       "      <td>21730</td>\n",
       "      <td>6</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>HAND WARMER UNION JACK</td>\n",
       "      <td>12/1/2010 8:28</td>\n",
       "      <td>536366</td>\n",
       "      <td>22633</td>\n",
       "      <td>6</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  customer_id                         description  \\\n",
       "0  United Kingdom        17850  WHITE HANGING HEART T-LIGHT HOLDER   \n",
       "1  United Kingdom        17850                 WHITE METAL LANTERN   \n",
       "2  United Kingdom        17850        SET 7 BABUSHKA NESTING BOXES   \n",
       "3  United Kingdom        17850   GLASS STAR FROSTED T-LIGHT HOLDER   \n",
       "4  United Kingdom        17850              HAND WARMER UNION JACK   \n",
       "\n",
       "     invoice_date invoice_no product_id  quantity  unit_price  \n",
       "0  12/1/2010 8:26     536365     85123A         6        2.55  \n",
       "1  12/1/2010 8:26     536365      71053         6        3.39  \n",
       "2  12/1/2010 8:26     536365      22752         2        7.65  \n",
       "3  12/1/2010 8:26     536365      21730         6        4.25  \n",
       "4  12/1/2010 8:28     536366      22633         6        1.85  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Remove some features and drop negative quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I'll treat this problem like a typical collaborative filtering problem. The only catch is that we don't have any explicit feedback, so we'll have to use the quantity of purchases (implicit feedback) instead. I perform the following preprocessing steps I perform to start:\n",
    "\n",
    "- Remove all the features except for the one's I need for collaborative filtering. \n",
    "- Aggregate all the quantities purchased of each product by each customer. This will be the implicit feedback used for training the model.\n",
    "- Set zero quantities to one. This assumes that the customer is still more likely to buy these products than one's they've never bought before.\n",
    "- Remove negative quantities. This assumes that customers have a negative preference for products that we've seen them return more of than they've purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only keep the customers, products, and quantity purchased.\n",
    "df = df_raw[['customer_id','product_id','quantity']]\n",
    "# This aggregates all the quantities purchased for each customer and product.\n",
    "df = df.groupby(['customer_id','product_id']).sum().reset_index()\n",
    "# Set zoer quantity sums to one.\n",
    "df.quantity = df.quantity.apply(lambda x: 1 if x==0 else x)\n",
    "# Remove negative quantities. \n",
    "df = df.query('quantity > 0').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>23166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>16008</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12347</td>\n",
       "      <td>17021</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12347</td>\n",
       "      <td>20665</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12347</td>\n",
       "      <td>20719</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id product_id  quantity\n",
       "0        12346      23166         1\n",
       "1        12347      16008        24\n",
       "2        12347      17021        36\n",
       "3        12347      20665         6\n",
       "4        12347      20719        40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Encode customer and product ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next I encode the customer and product ids. All the models used below will create vector representations of each product and each customer. These vectors are stored either in a matrices rows or columns. By encoding the customers and products with unique integers, we can store their respective vectors at the matrix row/column which corresponds with their encoded name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "    def __init__(self, col):\n",
    "        self.names = col.unique()\n",
    "        self.length = len(self.names)\n",
    "        self.name2idx = {name:idx for idx,name in enumerate(self.names)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __call__(self,name):\n",
    "        return self.name2idx[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enc_customers = Encoder(df['customer_id'])\n",
    "enc_products = Encoder(df['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_customers = len(enc_customers)\n",
    "n_products = len(enc_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.customer_id = df.customer_id.apply(lambda x: enc_customers(x))\n",
    "df.product_id = df.product_id.apply(lambda x: enc_products(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id  quantity\n",
       "0            0           0         1\n",
       "1            1           1        24\n",
       "2            1           2        36\n",
       "3            1           3         6\n",
       "4            1           4        40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next I split the data into a training and a validation set. The training set will be what the model sees during training, and then we'll evaluate the performance of the model on the validation set. This is done because we want a model which can predict well on new data which it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_val_idxs(idxs, pc):\n",
    "    np.random.shuffle(idxs)\n",
    "    val_idxs = idxs[0:int(pc*len(idxs))]\n",
    "    return np.array(val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# choose random subset for validation\n",
    "val_percentage = 0.2\n",
    "val_idxs = get_val_idxs(list(df.index), val_percentage)\n",
    "mask = np.zeros(len(df),dtype=bool)\n",
    "mask[val_idxs] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create validation and training set\n",
    "df_val = df[mask]\n",
    "df_trn = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_users = df_val.customer_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a sparse matrix representation of the various datasets. \n",
    "\n",
    "The data that we have only includes a very small fraction of the entire set of customer/product combinations possible. For training our model, we'll use the fact that a particular user hasn't bought a particular product as an indication that they have a lower preference for that item, and are therefore less likely to buy it in the future. To represent this, we create a sparse matrix, where each row is a customer and each column is a product. This matrix will have zeros at all the customer/product locations that aren't included in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sparse matrix for training data\n",
    "sparse_trn = sparse.csr_matrix(\n",
    "    (df_trn.quantity, (df_trn.customer_id, df_trn.product_id)), \n",
    "    shape=(n_customers, n_products))\n",
    "# sparse matrix for validation data\n",
    "sparse_val = sparse.csr_matrix(\n",
    "    (df_val.quantity, (df_val.customer_id, df_val.product_id)), \n",
    "    shape=(n_customers, n_products))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The metric used for this problem is area under the ROC curve. A greater area under the curve means we are recommending items that end up being purchased near the top of the list of recommended products.\n",
    "\n",
    "This metric only works with binary classification problem's, so we'll have to change our validation data to make this metric work. Instead of comparing to a validation dataset with quantities purchased for each item, we'll convert it into a binary preference matrix, where products that a customer has bought are represented with a one, and one's they haven't bought are represented with a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sparse matrix for validation using binary representation\n",
    "sparse_val_bin = sparse.csr_matrix(\n",
    "    (df_val.quantity.apply(lambda x: 1), (df_val.customer_id, df_val.product_id)), \n",
    "    shape=(n_customers, n_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def mean_auc(pred, true, sparse_trn, val_users):\n",
    "    scores = []\n",
    "    # iterate through customers in the validation set\n",
    "    for user in val_users: \n",
    "        # Only predict on user-item pairs which weren't seen during training.\n",
    "        user_row_trn = sparse_trn[user,:].toarray().reshape(-1) \n",
    "        unseen_inds = np.where(user_row_trn == 0) \n",
    "        # Get user predicted and true purchase arrays\n",
    "        y_pred = pred[user,:].toarray()[0][unseen_inds]\n",
    "        y_true = true[user,:].toarray()[0][unseen_inds]\n",
    "        # Calculate area under ROC\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        scores.append(auc(fpr, tpr)) \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before creating any models, it's always a good idea to create a baseline to measure model performance against. What I'll use as a baseline here is the mean quantity purchased over all users for each product. This roughly represents the quantity of each product that the average user will purchase. A recommender system which uses this baseline would just be ranking the items by popularity and would do so in the same way for each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_quantity = np.array(sparse_trn.mean(axis = 0)).reshape(-1)\n",
    "# create matrix which has a copy of the above vector at each customer row\n",
    "pred_mat = np.full((n_customers,n_products),mean_quantity)\n",
    "# convert matrix to sparse representation\n",
    "sparse_pred = sparse.csr_matrix(pred_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.7789\n"
     ]
    }
   ],
   "source": [
    "# AUROC\n",
    "score = mean_auc(sparse_pred, sparse_val_bin, sparse_trn, val_users)\n",
    "print('Area under ROC: {:0.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first model tried is Alternating Least Squares. What the algorithm tries to do is find a vector for each customer and a vector for each product such that their inner product is that customers preference for that product. This is a common technique for collaborative filtering problems. What differentiates this algorithm is the way in which it optimizes the cost function (see this [paper](http://yifanhu.net/PUB/cf.pdf) by Hu, Koren, and Volinsky for the details). At each step in the optimization, you alternate between holding the customer-vectors fixed while re-computing the product-vectors and holding the product-vectors fixed while re-computing the customer-vectors. This approach allows for much faster computing of the customer and product vectors than many others, such as stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ALSmodel():\n",
    "    def __init__(self, alpha=15, factors=10, regularization=0, iterations=1):\n",
    "        self.alpha = alpha\n",
    "        self.factors = factors\n",
    "        self.regularization = regularization\n",
    "        self.iterations = iterations\n",
    "        self.model = implicit.als.AlternatingLeastSquares(factors=self.factors, \n",
    "                                                        regularization=self.regularization, \n",
    "                                                        iterations=self.iterations)\n",
    "    def fit(self, sparse_mat):\n",
    "        \"\"\"Fit the model to the matrix provided\n",
    "        \n",
    "        Once the model has fit to the matrix,\n",
    "        the computed user and item vectors are store\n",
    "        \n",
    "        Arguments:\n",
    "        sparse_mat -- sparse matrix to fit to\n",
    "        \"\"\"\n",
    "        self.model.fit(sparse_mat.T*self.alpha)\n",
    "        self.user_vecs = sparse.csr_matrix(self.model.user_factors)\n",
    "        self.item_vecs = sparse.csr_matrix(self.model.item_factors.T)\n",
    "            \n",
    "    def pred_mat(self):\n",
    "        \"\"\" \n",
    "        Predict and return every user-item\n",
    "        pair as a numpy array\n",
    "        \"\"\"\n",
    "        pred = np.matmul(self.user_vecs.toarray(),self.item_vecs.toarray())\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "als_model = ALSmodel(alpha=15,factors=50,\n",
    "                     regularization=0.1,\n",
    "                     iterations=50)\n",
    "# Fit to training data\n",
    "als_model.fit(sparse_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict on all customer-product pairs\n",
    "pred_mat = als_model.pred_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.8347\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC\n",
    "score = mean_auc(sparse.csr_matrix(pred_mat), sparse_val_bin, sparse_trn, val_users)\n",
    "print('Area under ROC: {:0.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SGD-nonzero model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model also creates customer and product vectors whose dot product estimates the customer's preference for a product. But this approach randomly initializes the embeddings (customer/product vector) and then uses Stochastic Gradient Descent (SGD) to optimize them. This model will only learn on the customer-product examples included in the dataset, unlike ALS which assumes the customer preference for customer-product pairs it hasn't seen are zero. The hope here is that the data provided has enough information about the user and products such that useful representations can be found which can predict preferences on unseen customer-product pairs. The main motivation for only including customer-product pairs seen in the data is to reduce training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Reshape, Merge, Dot, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CFModel(Sequential):\n",
    "\n",
    "    def __init__(self, n_customers, n_products, k_factors, **kwargs):\n",
    "        self.n_customers = n_customers\n",
    "        self.n_products = n_products\n",
    "        self.user = Sequential()\n",
    "        self.user.add(Embedding(n_customers, k_factors, input_length=1))\n",
    "        self.user.add(Reshape((k_factors,)))\n",
    "        self.item = Sequential()\n",
    "        self.item.add(Embedding(n_products, k_factors, input_length=1))\n",
    "        self.item.add(Reshape((k_factors,)))\n",
    "        super(CFModel, self).__init__(**kwargs)\n",
    "        self.add(Merge([self.user, self.item], mode='dot', dot_axes=1))\n",
    "        self.add(Dense(1, activation='linear'))\n",
    "\n",
    "    def pred(self, user_id, item_id):\n",
    "        return self.predict([np.array([user_id]), np.array([item_id])])[0][0]\n",
    "    \n",
    "    def pred_vec(self, user_id):\n",
    "        res = self.predict([np.array([user_id]*self.n_products),\n",
    "                            np.arange(self.n_products)])\n",
    "        return res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "k_factors = 50\n",
    "emb_nonzero = CFModel(n_customers, n_products, k_factors)\n",
    "emb_nonzero.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170340 samples, validate on 42584 samples\n",
      "Epoch 1/1\n",
      "170340/170340 [==============================] - 7s 41us/step - loss: 9170.9965 - val_loss: 11697.4718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f749c1402e8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_nonzero.fit([df_trn.customer_id, df_trn.product_id], df_trn.quantity, epochs=1, batch_size=128, \n",
    "               validation_data=([df_val.customer_id, df_val.product_id], df_val.quantity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# unravel sparse matrix and indices to feed into model\n",
    "product_idxs = np.full((n_customers,n_products),np.arange(n_products))\n",
    "customer_idxs = np.full((n_products,n_customers),np.arange(n_customers)).T\n",
    "product_idxs = product_idxs.ravel()\n",
    "customer_idxs = customer_idxs.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# predict on all customer-product pairs\n",
    "pred = emb_nonzero.predict([customer_idxs, product_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert predictions to sparse matrix\n",
    "pred_mat = sparse.csr_matrix(\n",
    "    (pred.flatten(), (customer_idxs, product_idxs)), \n",
    "    shape=(n_customers, n_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.7134\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC\n",
    "score = mean_auc(pred_mat, sparse_val_bin, sparse_trn, val_users)\n",
    "print('Area under ROC: {:0.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SGD-full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model is the same as the one above, except we now include the customer-product pairs which aren't in the dataset, and assumes preference for these pairs are zero (same as ALS). Now the model will have all the information available to it that the ALS model has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "k_factors = 50\n",
    "model = CFModel(n_customers, n_products, k_factors)\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "quantities = sparse_trn.toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "15857430/15857430 [==============================] - 668s 42us/step - loss: 98.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f749c1636d8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([customer_idxs, product_idxs], quantities, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# predict on all customer-product pairs\n",
    "pred = model.predict([customer_idxs, product_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert predictions to sparse matrix\n",
    "pred_mat = sparse.csr_matrix(\n",
    "    (pred.flatten(), (customer_idxs, product_idxs)), \n",
    "    shape=(n_customers, n_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.6770\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC\n",
    "score = mean_auc(pred_mat, sparse_val_bin, sparse_trn, val_users)\n",
    "print('Area under ROC: {:0.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Model | AUROC \n",
    "--- | --- | \n",
    "ALS | 0.8347 | \n",
    "Baseline | 0.7789 |\n",
    "SGD-nonzero | 0.7134 |\n",
    "SGD-full | 0.6770 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ALS is our winner! Followed by the baseline, SGD-nonzero, and SGD-full. \n",
    "\n",
    "ALS is an algorithm which was crafted specifically for these kinds of implicit rating problems. From the outset, it seemed likely that this model would outperform others, but I wanted to try out some embeddings learned through SGD to see how they held up. \n",
    "\n",
    "The first SGD optimized model (SGD-nonzero) I tried was trained only on the labeled data we have. It didn't include missing customer-product pairs as zero rated examples as the ALS algorithm does. This is an approach often used for problems with explicit ratings. The idea here is that, given the relative ratings between products and users, the model might still be able to learn embeddings which are useful for predicting relative preferences between products for a user. This approach stalled out in performance pretty quickly, which is reflected in it's low performance relative to the baseline.\n",
    "\n",
    "SGD-full was trained on the entire sparse training matrix. So this one did receive the zero rating customer-product pairs to learn from. This model performed wost of all and took *way* longer to train than the ALS model. A single epoch took about 10 minutes, while the ALS was able to complete 50 iterations in seconds. I think this is performing worse that SGD-partial because the information gained from the non-zero customer-product pairs is being diluted by all the zero examples. To be fair, the model only trained for one epoch, and it might be the case that it's performance will steadly rise given enough time. But it might also be the case where the zero preference examples keep pushing the embeddings toward predictions of zero and never learns useful representations. In any case, given how long it takes to train, I think it's safe to say that for practical purposes ALS would be the way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save ALS model predictions\n",
    "pred_mat = als_model.pred_mat()\n",
    "np.save('user_profiles', pred_mat)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
